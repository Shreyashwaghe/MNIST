{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#optional, only for classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training data\n",
    "training_data_obj = pd.read_csv('mnist_train.csv',header=None)\n",
    "traindata = np.array(training_data_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=traindata[:,1:].T\n",
    "#print(X_train,X_train.shape)\n",
    "X_train=X_train/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = traindata[:,0]\n",
    "Y_train = Y_train.reshape(1,Y_train.shape[0])\n",
    "#print(Y_train)\n",
    "\n",
    "\n",
    "Y_prob=np.zeros((10,60000))\n",
    "for i in range(0,60000):\n",
    "    a=Y_train[0,i]\n",
    "   # print(a)\n",
    "    Y_prob[a,i] = 1\n",
    "    #print(i)\n",
    "ans_train_real=Y_train\n",
    "#print(Y_prob)    \n",
    "Y_train=Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "   \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    " \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA):\n",
    "   \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ=np.ones((dA.shape))\n",
    "    dZ[dA <= 0] = 0\n",
    "    \n",
    "    #assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to initialize weights\n",
    "def initialize_parameters_deep(layer_dims): \n",
    "\n",
    "    W = {}\n",
    "    b = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        W[l] = np.random.randn(layer_dims[l], layer_dims[l-1])  / np.sqrt(layer_dims[l-1]) \n",
    "        #print('W',l,layer_dims[l], layer_dims[l-1])\n",
    "        b[l] = np.zeros((layer_dims[l], 1))\n",
    "       \n",
    "        \n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 cost:  2.3403253176039813 \t Accuracy : 0.08603333333333334\n",
      "Iteration 10 cost:  1.4618402246632094 \t Accuracy : 0.6465666666666668\n",
      "Iteration 20 cost:  0.6175772809258735 \t Accuracy : 0.8021000000000003\n",
      "Iteration 30 cost:  0.6057881324171762 \t Accuracy : 0.8043000000000002\n",
      "Iteration 40 cost:  0.4023487748612528 \t Accuracy : 0.8855333333333335\n",
      "Iteration 50 cost:  0.3847708763375586 \t Accuracy : 0.8870666666666669\n",
      "Iteration 60 cost:  0.3473927235461286 \t Accuracy : 0.9003333333333335\n",
      "Iteration 70 cost:  0.32036583745788494 \t Accuracy : 0.9095833333333335\n",
      "Iteration 80 cost:  0.3053089152075269 \t Accuracy : 0.9136333333333336\n",
      "Iteration 90 cost:  0.2931123369342015 \t Accuracy : 0.9170333333333336\n",
      "Iteration 100 cost:  0.28250682260073484 \t Accuracy : 0.9201333333333336\n",
      "Iteration 110 cost:  0.2730672203743858 \t Accuracy : 0.9229166666666668\n",
      "Iteration 120 cost:  0.264522820328194 \t Accuracy : 0.925666666666667\n",
      "Iteration 130 cost:  0.2566900172729241 \t Accuracy : 0.9281166666666669\n",
      "Iteration 140 cost:  0.24948535505119393 \t Accuracy : 0.9300333333333336\n",
      "Iteration 150 cost:  0.24279030152281364 \t Accuracy : 0.9319333333333337\n",
      "Iteration 160 cost:  0.23654661572122035 \t Accuracy : 0.9341333333333336\n",
      "Iteration 170 cost:  0.2307026506009516 \t Accuracy : 0.9356166666666669\n",
      "Iteration 180 cost:  0.22520514832943306 \t Accuracy : 0.9368833333333333\n",
      "Iteration 190 cost:  0.22001108266216876 \t Accuracy : 0.9386000000000001\n",
      "Iteration 200 cost:  0.21509569655202254 \t Accuracy : 0.9398500000000002\n",
      "Iteration 210 cost:  0.21043516553349595 \t Accuracy : 0.9411500000000002\n",
      "Iteration 220 cost:  0.206009388939674 \t Accuracy : 0.9423833333333336\n",
      "Iteration 230 cost:  0.2017992877028805 \t Accuracy : 0.9435666666666671\n",
      "Iteration 240 cost:  0.1977889498502926 \t Accuracy : 0.9448333333333335\n",
      "Iteration 250 cost:  0.19395084456019868 \t Accuracy : 0.9458500000000005\n",
      "Iteration 260 cost:  0.1902772688582147 \t Accuracy : 0.9468000000000004\n",
      "Iteration 270 cost:  0.1867589439718358 \t Accuracy : 0.9478333333333336\n",
      "Iteration 280 cost:  0.1833904152947601 \t Accuracy : 0.9487333333333337\n",
      "Iteration 290 cost:  0.18015586105865297 \t Accuracy : 0.9495166666666669\n",
      "Iteration 300 cost:  0.17704968592587372 \t Accuracy : 0.9505666666666669\n",
      "Iteration 310 cost:  0.17406381110422703 \t Accuracy : 0.9513000000000003\n",
      "Iteration 320 cost:  0.1711932402888698 \t Accuracy : 0.952066666666667\n",
      "Iteration 330 cost:  0.1684292910660805 \t Accuracy : 0.9526833333333337\n",
      "Iteration 340 cost:  0.1657580944879538 \t Accuracy : 0.9532333333333336\n",
      "Iteration 350 cost:  0.16317432656819197 \t Accuracy : 0.9541333333333336\n",
      "Iteration 360 cost:  0.16067484151262235 \t Accuracy : 0.954916666666667\n",
      "Iteration 370 cost:  0.15825397099301675 \t Accuracy : 0.9556833333333337\n",
      "Iteration 380 cost:  0.1559090431754009 \t Accuracy : 0.9561000000000003\n",
      "Iteration 390 cost:  0.15363273509820008 \t Accuracy : 0.9568000000000002\n",
      "Iteration 400 cost:  0.1514259529312723 \t Accuracy : 0.9574500000000001\n",
      "Iteration 410 cost:  0.14928836806558002 \t Accuracy : 0.9581166666666667\n",
      "Iteration 420 cost:  0.1472119433899024 \t Accuracy : 0.9587333333333334\n",
      "Iteration 430 cost:  0.1451936621409381 \t Accuracy : 0.9593500000000005\n",
      "Iteration 440 cost:  0.14323136400661382 \t Accuracy : 0.9598000000000003\n",
      "Iteration 450 cost:  0.1413240091211969 \t Accuracy : 0.9603833333333335\n",
      "Iteration 460 cost:  0.13946922162500275 \t Accuracy : 0.9611833333333335\n",
      "Iteration 470 cost:  0.13766468242527105 \t Accuracy : 0.9616166666666668\n",
      "Iteration 480 cost:  0.135904979717587 \t Accuracy : 0.962116666666667\n",
      "Iteration 490 cost:  0.1341886229775464 \t Accuracy : 0.9626500000000002\n",
      "Iteration 500 cost:  0.13251632148649914 \t Accuracy : 0.9632333333333336\n",
      "Iteration 510 cost:  0.13088609306506585 \t Accuracy : 0.9637500000000002\n",
      "Iteration 520 cost:  0.12929551458623847 \t Accuracy : 0.9642000000000003\n",
      "Iteration 530 cost:  0.12774514425734423 \t Accuracy : 0.9647000000000002\n",
      "Iteration 540 cost:  0.12623092262060573 \t Accuracy : 0.9651166666666668\n",
      "Iteration 550 cost:  0.12475243723739284 \t Accuracy : 0.9656166666666669\n",
      "Iteration 560 cost:  0.12330720020102394 \t Accuracy : 0.9659333333333334\n",
      "Iteration 570 cost:  0.1218897989913757 \t Accuracy : 0.9662666666666668\n",
      "Iteration 580 cost:  0.1205034692841454 \t Accuracy : 0.9668166666666668\n",
      "Iteration 590 cost:  0.11914610002307109 \t Accuracy : 0.9674166666666669\n",
      "Iteration 600 cost:  0.11781760930239825 \t Accuracy : 0.9679500000000001\n",
      "Iteration 610 cost:  0.11651770693588014 \t Accuracy : 0.9683500000000003\n",
      "Iteration 620 cost:  0.11524627967162492 \t Accuracy : 0.9687000000000001\n",
      "Iteration 630 cost:  0.11400291204910931 \t Accuracy : 0.969016666666667\n",
      "Iteration 640 cost:  0.11278532883734552 \t Accuracy : 0.9693500000000003\n",
      "Iteration 650 cost:  0.11159124490434573 \t Accuracy : 0.9697666666666669\n",
      "Iteration 660 cost:  0.11042079726929808 \t Accuracy : 0.9700000000000002\n",
      "Iteration 670 cost:  0.10927426111813399 \t Accuracy : 0.9703333333333335\n",
      "Iteration 680 cost:  0.10815141273357556 \t Accuracy : 0.9705500000000001\n",
      "Iteration 690 cost:  0.10704932843221511 \t Accuracy : 0.9710833333333336\n",
      "Iteration 700 cost:  0.10596942467687262 \t Accuracy : 0.9715000000000003\n",
      "Iteration 710 cost:  0.10491122884073584 \t Accuracy : 0.9718500000000002\n",
      "Iteration 720 cost:  0.10387328600201456 \t Accuracy : 0.9721000000000002\n",
      "Iteration 730 cost:  0.1028547278034252 \t Accuracy : 0.9723833333333335\n",
      "Iteration 740 cost:  0.10185461726999377 \t Accuracy : 0.9727000000000001\n",
      "Iteration 750 cost:  0.10087219909741746 \t Accuracy : 0.9731666666666667\n",
      "Iteration 760 cost:  0.09990823475611553 \t Accuracy : 0.9734833333333335\n",
      "Iteration 770 cost:  0.09896184338054499 \t Accuracy : 0.9736333333333334\n",
      "Iteration 780 cost:  0.09803427341659093 \t Accuracy : 0.9739666666666668\n",
      "Iteration 790 cost:  0.09712355480470199 \t Accuracy : 0.9741833333333334\n",
      "Iteration 800 cost:  0.09622839563350591 \t Accuracy : 0.9743333333333334\n",
      "Iteration 810 cost:  0.09534848879660299 \t Accuracy : 0.9746166666666668\n",
      "Iteration 820 cost:  0.09448286305239662 \t Accuracy : 0.9748833333333335\n",
      "Iteration 830 cost:  0.09363253210008708 \t Accuracy : 0.975066666666667\n",
      "Iteration 840 cost:  0.0927965549755824 \t Accuracy : 0.9752166666666668\n",
      "Iteration 850 cost:  0.09197453493522398 \t Accuracy : 0.9754333333333334\n",
      "Iteration 860 cost:  0.09116583433408003 \t Accuracy : 0.9756000000000002\n",
      "Iteration 870 cost:  0.09036962943608294 \t Accuracy : 0.9758333333333336\n",
      "Iteration 880 cost:  0.08958586433130679 \t Accuracy : 0.9760333333333335\n",
      "Iteration 890 cost:  0.08881586264777021 \t Accuracy : 0.9761666666666668\n",
      "Iteration 900 cost:  0.0880591538219655 \t Accuracy : 0.9763333333333335\n",
      "Iteration 910 cost:  0.08731404439503723 \t Accuracy : 0.9764333333333335\n",
      "Iteration 920 cost:  0.08658081939987183 \t Accuracy : 0.9766166666666669\n",
      "Iteration 930 cost:  0.08585859279617684 \t Accuracy : 0.9767666666666668\n",
      "Iteration 940 cost:  0.08514792297637944 \t Accuracy : 0.9768500000000002\n",
      "Iteration 950 cost:  0.08444737913358542 \t Accuracy : 0.9770000000000001\n",
      "Iteration 960 cost:  0.0837570389988493 \t Accuracy : 0.9772000000000003\n",
      "Iteration 970 cost:  0.08307718543526285 \t Accuracy : 0.9773666666666669\n",
      "Iteration 980 cost:  0.08240808524614497 \t Accuracy : 0.9775333333333336\n",
      "Iteration 990 cost:  0.08174917284825445 \t Accuracy : 0.9777666666666669\n",
      "Iteration 1000 cost:  0.08109941814679997 \t Accuracy : 0.9779833333333336\n",
      "Iteration 1010 cost:  0.08045836917910446 \t Accuracy : 0.9781666666666669\n",
      "Iteration 1020 cost:  0.07982626356758894 \t Accuracy : 0.9782833333333336\n",
      "Iteration 1030 cost:  0.07920285386107344 \t Accuracy : 0.9784500000000003\n",
      "Iteration 1040 cost:  0.07858810567000779 \t Accuracy : 0.9786000000000002\n",
      "Iteration 1050 cost:  0.07798210928435736 \t Accuracy : 0.9787833333333337\n",
      "Iteration 1060 cost:  0.07738385660232357 \t Accuracy : 0.9790166666666669\n",
      "Iteration 1070 cost:  0.07679257572437899 \t Accuracy : 0.9791166666666669\n",
      "Iteration 1080 cost:  0.07620984113088297 \t Accuracy : 0.9792833333333335\n",
      "Iteration 1090 cost:  0.07563460476105276 \t Accuracy : 0.9795166666666668\n",
      "Iteration 1100 cost:  0.07506704883750644 \t Accuracy : 0.9796833333333335\n",
      "Iteration 1110 cost:  0.07450700998852353 \t Accuracy : 0.9798333333333336\n",
      "Iteration 1120 cost:  0.07395335201674556 \t Accuracy : 0.9798833333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1130 cost:  0.07340683246523645 \t Accuracy : 0.9800833333333335\n",
      "Iteration 1140 cost:  0.07286696907393378 \t Accuracy : 0.9802500000000002\n",
      "Iteration 1150 cost:  0.07233400552792235 \t Accuracy : 0.9805500000000001\n",
      "Iteration 1160 cost:  0.07180720015499036 \t Accuracy : 0.9807166666666669\n",
      "Iteration 1170 cost:  0.07128751013777111 \t Accuracy : 0.9808166666666668\n",
      "Iteration 1180 cost:  0.07077493753655453 \t Accuracy : 0.9809500000000001\n",
      "Iteration 1190 cost:  0.07026875366342189 \t Accuracy : 0.9809833333333334\n",
      "Iteration 1200 cost:  0.06976862955338663 \t Accuracy : 0.9811500000000001\n",
      "Iteration 1210 cost:  0.06927488070783969 \t Accuracy : 0.9812500000000003\n",
      "Iteration 1220 cost:  0.06878718840492933 \t Accuracy : 0.9814833333333336\n",
      "Iteration 1230 cost:  0.06830440934439314 \t Accuracy : 0.9817000000000002\n",
      "Iteration 1240 cost:  0.06782695733218645 \t Accuracy : 0.9817666666666669\n",
      "Iteration 1250 cost:  0.06735529432540296 \t Accuracy : 0.9819000000000002\n",
      "Iteration 1260 cost:  0.06688915185815199 \t Accuracy : 0.9821000000000002\n",
      "Iteration 1270 cost:  0.06642878658952797 \t Accuracy : 0.9821666666666669\n",
      "Iteration 1280 cost:  0.06597426291008879 \t Accuracy : 0.9823000000000002\n",
      "Iteration 1290 cost:  0.06552476523742905 \t Accuracy : 0.9824000000000002\n",
      "Iteration 1300 cost:  0.06508046344700728 \t Accuracy : 0.9825333333333336\n",
      "Iteration 1310 cost:  0.06464172278901335 \t Accuracy : 0.9826333333333335\n",
      "Iteration 1320 cost:  0.06420867715114172 \t Accuracy : 0.9827833333333336\n",
      "Iteration 1330 cost:  0.06378049811344305 \t Accuracy : 0.9828333333333336\n",
      "Iteration 1340 cost:  0.06335730645911175 \t Accuracy : 0.9830333333333336\n",
      "Iteration 1350 cost:  0.06293900739338053 \t Accuracy : 0.9832333333333334\n",
      "Iteration 1360 cost:  0.06252576759820541 \t Accuracy : 0.9833500000000002\n",
      "Iteration 1370 cost:  0.06211739189019274 \t Accuracy : 0.9834833333333336\n",
      "Iteration 1380 cost:  0.06171367603260731 \t Accuracy : 0.9835000000000002\n",
      "Iteration 1390 cost:  0.06131428717889321 \t Accuracy : 0.9835833333333334\n",
      "Iteration 1400 cost:  0.06091875454942593 \t Accuracy : 0.9836833333333335\n",
      "Iteration 1410 cost:  0.06052756407399436 \t Accuracy : 0.9837333333333335\n",
      "Iteration 1420 cost:  0.0601404804216495 \t Accuracy : 0.9839166666666669\n",
      "Iteration 1430 cost:  0.059757050967175644 \t Accuracy : 0.9840833333333334\n",
      "Iteration 1440 cost:  0.059378033138521635 \t Accuracy : 0.9842666666666668\n",
      "Iteration 1450 cost:  0.059003132244341616 \t Accuracy : 0.9844333333333335\n",
      "Iteration 1460 cost:  0.05863205595846888 \t Accuracy : 0.9845500000000001\n",
      "Iteration 1470 cost:  0.05826461433551363 \t Accuracy : 0.9846500000000001\n",
      "Iteration 1480 cost:  0.05790106451800925 \t Accuracy : 0.9847333333333335\n",
      "Iteration 1490 cost:  0.05754071338314017 \t Accuracy : 0.9849000000000002\n",
      "Iteration 1500 cost:  0.05718399231553968 \t Accuracy : 0.9849333333333334\n",
      "Iteration 1510 cost:  0.0568308221273886 \t Accuracy : 0.9850333333333334\n",
      "Iteration 1520 cost:  0.05648118245616345 \t Accuracy : 0.9851166666666669\n",
      "Iteration 1530 cost:  0.05613518188419789 \t Accuracy : 0.9852500000000002\n",
      "Iteration 1540 cost:  0.05579314159571373 \t Accuracy : 0.9854000000000003\n",
      "Iteration 1550 cost:  0.055454393954692476 \t Accuracy : 0.9855500000000004\n",
      "Iteration 1560 cost:  0.055118960775618925 \t Accuracy : 0.9856833333333335\n",
      "Iteration 1570 cost:  0.05478695998447046 \t Accuracy : 0.9857833333333337\n",
      "Iteration 1580 cost:  0.054458409907246604 \t Accuracy : 0.9859500000000003\n",
      "Iteration 1590 cost:  0.05413288449118615 \t Accuracy : 0.9860500000000003\n",
      "Iteration 1600 cost:  0.05381014145809528 \t Accuracy : 0.9861333333333335\n",
      "Iteration 1610 cost:  0.0534905602149192 \t Accuracy : 0.986216666666667\n",
      "Iteration 1620 cost:  0.053174443124027186 \t Accuracy : 0.9863166666666671\n",
      "Iteration 1630 cost:  0.0528612425112434 \t Accuracy : 0.9865333333333336\n",
      "Iteration 1640 cost:  0.05255080081620237 \t Accuracy : 0.9865833333333337\n",
      "Iteration 1650 cost:  0.052243290227014384 \t Accuracy : 0.9867833333333337\n",
      "Iteration 1660 cost:  0.05193859293084952 \t Accuracy : 0.9868333333333336\n",
      "Iteration 1670 cost:  0.051636706200102654 \t Accuracy : 0.9868666666666669\n",
      "Iteration 1680 cost:  0.05133768705628467 \t Accuracy : 0.9869666666666669\n",
      "Iteration 1690 cost:  0.05104110677345972 \t Accuracy : 0.987016666666667\n",
      "Iteration 1700 cost:  0.05074698966253233 \t Accuracy : 0.987166666666667\n",
      "Iteration 1710 cost:  0.05045518657438779 \t Accuracy : 0.9872666666666668\n",
      "Iteration 1720 cost:  0.05016588782791621 \t Accuracy : 0.9873333333333336\n",
      "Iteration 1730 cost:  0.04987898923477658 \t Accuracy : 0.9873500000000002\n",
      "Iteration 1740 cost:  0.04959441404111356 \t Accuracy : 0.9873666666666668\n",
      "Iteration 1750 cost:  0.049312378871794314 \t Accuracy : 0.9874333333333335\n",
      "Iteration 1760 cost:  0.049032938217413495 \t Accuracy : 0.9875500000000003\n",
      "Iteration 1770 cost:  0.0487557475389297 \t Accuracy : 0.9875833333333336\n",
      "Iteration 1780 cost:  0.04848098824238344 \t Accuracy : 0.9876833333333336\n",
      "Iteration 1790 cost:  0.0482087709629513 \t Accuracy : 0.9877666666666668\n",
      "Iteration 1800 cost:  0.0479391658330887 \t Accuracy : 0.9878500000000001\n",
      "Iteration 1810 cost:  0.0476719630952069 \t Accuracy : 0.9880333333333335\n",
      "Iteration 1820 cost:  0.04740723722818576 \t Accuracy : 0.9880833333333334\n",
      "Iteration 1830 cost:  0.047144857853854694 \t Accuracy : 0.9882000000000001\n",
      "Iteration 1840 cost:  0.046884649793069465 \t Accuracy : 0.9883500000000002\n",
      "Iteration 1850 cost:  0.04662641962670072 \t Accuracy : 0.9884166666666668\n",
      "Iteration 1860 cost:  0.04637034591425214 \t Accuracy : 0.9884833333333335\n",
      "Iteration 1870 cost:  0.04611654762009707 \t Accuracy : 0.9885333333333335\n",
      "Iteration 1880 cost:  0.04586472525943763 \t Accuracy : 0.9886000000000001\n",
      "Iteration 1890 cost:  0.04561501006358594 \t Accuracy : 0.9887000000000002\n",
      "Iteration 1900 cost:  0.045367231276956334 \t Accuracy : 0.9888166666666669\n",
      "Iteration 1910 cost:  0.045121352868397864 \t Accuracy : 0.9889333333333336\n",
      "Iteration 1920 cost:  0.04487738930572085 \t Accuracy : 0.9890333333333335\n",
      "Iteration 1930 cost:  0.04463560158716989 \t Accuracy : 0.9891000000000002\n",
      "Iteration 1940 cost:  0.044395833890787655 \t Accuracy : 0.9891500000000002\n",
      "Iteration 1950 cost:  0.04415797349177129 \t Accuracy : 0.9892333333333335\n",
      "Iteration 1960 cost:  0.0439220022834124 \t Accuracy : 0.9892666666666668\n",
      "Iteration 1970 cost:  0.043687761681802696 \t Accuracy : 0.9892833333333335\n",
      "Iteration 1980 cost:  0.04345482543210139 \t Accuracy : 0.9893166666666668\n",
      "Iteration 1990 cost:  0.043223697080436295 \t Accuracy : 0.9893833333333335\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cost: 0.043017148951029205\n",
      "Total Accuracy : 0.9893833333333335\n"
     ]
    }
   ],
   "source": [
    "#hyper_parameters\n",
    "learning_rate = 0.5    \n",
    "iterations=2000\n",
    "layers_dims = [784, 150, 10]  #only change the middle value(s) to change the size of hidden layers, like [784, 320, 80, 40, 10]\n",
    "L=len(layers_dims)\n",
    "m=X_train.shape[1]\n",
    "\n",
    "#dictionaries to store the parameters\n",
    "W={}\n",
    "b={}\n",
    "A={}\n",
    "Z={}\n",
    "dZ={}\n",
    "dW={}\n",
    "db={}\n",
    "dA={}\n",
    "\n",
    "#initialize weights and biases\n",
    "W,b=initialize_parameters_deep(layers_dims)\n",
    "\n",
    "#L -1 is done as to get number of relu layer\n",
    "L = L -1                 \n",
    "#print(L)\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "costs=[]\n",
    "accuracies=[]\n",
    "\n",
    "for j in range(iterations):\n",
    "    A[0]=X\n",
    "    \n",
    "    #calculating parameters for relu activation \n",
    "    for i in range(1,L):\n",
    "        #print(W[1])\n",
    "        Z[i] = np.matmul(W[i],A[i-1]) + b[i]\n",
    "        A[i] = relu(Z[i])\n",
    "        #print(i)\n",
    "    \n",
    "    #calculating parameters for softmax activation \n",
    "    Z[L] = np.matmul(W[L],A[L-1]) + b[L]\n",
    "    A[L] = np.exp(Z[L]) / np.sum(np.exp(Z[L]), axis=0)\n",
    "    #print('A',L,A[L].shape)\n",
    "    \n",
    "    #calculating cost\n",
    "    cost = compute_multiclass_loss(Y, A[L])\n",
    "    \n",
    "    #calculating derivatives for softmax layer\n",
    "    dZ[L] = A[L]-Y\n",
    "    dW[L] = (1./m) * np.matmul(dZ[L], A[L-1].T)\n",
    "    dA[L] = (-1./m) * np.sum(np.divide(Y,A[L]))\n",
    "    db[L] = (1./m) * np.sum(dZ[L], axis=1, keepdims=True)\n",
    "    #print(dW)\n",
    "    #print(L,dZ[L])\n",
    "    \n",
    "    #calculating derivatives for relu layer\n",
    "    for i in reversed(range(1,L)):\n",
    "        #print(i)\n",
    "        #print(dW)\n",
    "        dA[i] = np.matmul(W[i+1].T, dZ[i+1])\n",
    "        dZ[i] = dA[i] *relu_backward(Z[i])\n",
    "        dW[i] = (1./m) * np.matmul(dZ[i], A[i-1].T)\n",
    "        db[i] = (1./m) * np.sum(dZ[i], axis=1, keepdims=True)\n",
    "        \n",
    "        #print(i,dA.keys(),dZ.keys(),dW.keys(),db.keys())\n",
    "        #print()\n",
    "    \n",
    "    #updating weights and biases\n",
    "    for i in range(1,L+1):\n",
    "        #print('a',i)\n",
    "        #print(W[1])\n",
    "        W[i] = W[i] - learning_rate * dW[i]\n",
    "        b[i] = b[i] - learning_rate * db[i]\n",
    "    \n",
    "\n",
    "    if (j % 10 == 0):   #print cost,accuracy every 10th iteration\n",
    "        \n",
    "        predictions = np.argmax(A[L], axis=0)\n",
    "        labels = np.argmax(Y_train, axis=0)\n",
    "        \n",
    "        acc = np.sum((predictions == labels)/m)\n",
    "        print(\"Iteration\", j, \"cost: \", cost,'\\t Accuracy :',acc)\n",
    "        costs.append(cost)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        \n",
    "# plot the cost and accuracy\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.squeeze(accuracies))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "print(\"Final cost:\", cost)\n",
    "print('Total Accuracy :',np.sum((predictions == labels)/m))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5894    1    7    5    2    5   11    2    9   10]\n",
      " [   1 6693    7    5    6    4    5   17   17    9]\n",
      " [   2   15 5902   22    3    3    1   14    7    0]\n",
      " [   1    3    8 6035    1   16    0    4   13   11]\n",
      " [   1    7    7    1 5784    2   10   10    2   20]\n",
      " [   1    0    2   20    1 5355    5    1   12   10]\n",
      " [   9    2    2    0    8   11 5878    1   11    2]\n",
      " [   2   10   13   18    5    3    0 6197    1   21]\n",
      " [   6   10    8   12    3   12    8    3 5770    9]\n",
      " [   6    1    2   13   29   10    0   16    9 5857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      5946\n",
      "           1       0.99      0.99      0.99      6764\n",
      "           2       0.99      0.99      0.99      5969\n",
      "           3       0.98      0.99      0.99      6092\n",
      "           4       0.99      0.99      0.99      5844\n",
      "           5       0.99      0.99      0.99      5407\n",
      "           6       0.99      0.99      0.99      5924\n",
      "           7       0.99      0.99      0.99      6270\n",
      "           8       0.99      0.99      0.99      5841\n",
      "           9       0.98      0.99      0.99      5943\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "Final cost: 0.043017148951029205\n",
      "Total Accuracy : 0.9894166666666668\n"
     ]
    }
   ],
   "source": [
    "##Repeting the last iteration to see the final cost and accuracy\n",
    "#using the latest(best) Ws, bs values\n",
    "\n",
    "layers_dims = [784, 150, 10]\n",
    "L=len(layers_dims)-1\n",
    "m=X_train.shape[1]\n",
    "A[0]=X_train\n",
    "\n",
    "for i in range (1,L):\n",
    "    Z[i] = np.matmul(W[i], A[i-1]) + b[i]\n",
    "    A[i] = relu(Z[i])\n",
    "    \n",
    "Z[L] = np.matmul(W[L], A[L-1]) + b[L]\n",
    "A[L] = np.exp(Z[L]) / np.sum(np.exp(Z[L]), axis=0)\n",
    "\n",
    "predictions = np.argmax(A[L], axis=0)\n",
    "labels = np.argmax(Y_train, axis=0)\n",
    "#print(predictions,labels)\n",
    "\n",
    "#analysis report\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))\n",
    "print(\"Final cost:\", cost)\n",
    "print('Total Accuracy :',np.sum((predictions == labels)/m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test data\n",
    "testing_data_obj = pd.read_csv('mnist_test.csv',header=None)\n",
    "testdata = np.array(testing_data_obj)\n",
    "\n",
    "#test data input features\n",
    "X_test=testdata[:,1:].T\n",
    "#print(X_test,X_test.shape)\n",
    "X_test=X_test/255\n",
    "\n",
    "#test data output values\n",
    "Y_test = testdata[:,0]\n",
    "Y_test = Y_test.reshape(1,Y_test.shape[0])\n",
    "#print(Y_test,Y_test[0,0],Y_test.shape,testdata.shape)\n",
    "\n",
    "#one-hot encoding output values\n",
    "m=Y_test.shape[1]\n",
    "Y_prob=np.zeros((10,m))\n",
    "for i in range(0,m):\n",
    "    a=Y_test[0,i]\n",
    "   # print(a)\n",
    "    Y_prob[a,i] = 1\n",
    "    #print(i)\n",
    "ans_test_real=Y_test\n",
    "#print(Y_prob,Y_prob.shape)    \n",
    "Y_test=Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 969    0    5    0    2    3    4    1    3    3]\n",
      " [   0 1122    2    0    0    1    3    7    0    6]\n",
      " [   0    3  998    3    5    0    2    5    4    1]\n",
      " [   2    1    4  993    1    8    1    4    6    6]\n",
      " [   1    0    4    0  959    1    3    1    3    8]\n",
      " [   2    0    0    4    1  864    3    0    4    2]\n",
      " [   1    3    5    0    1    5  940    0    4    0]\n",
      " [   2    2    6    3    3    1    1 1001    4    6]\n",
      " [   2    4    8    4    1    5    1    2  944    3]\n",
      " [   1    0    0    3    9    4    0    7    2  974]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       990\n",
      "           1       0.99      0.98      0.99      1141\n",
      "           2       0.97      0.98      0.97      1021\n",
      "           3       0.98      0.97      0.98      1026\n",
      "           4       0.98      0.98      0.98       980\n",
      "           5       0.97      0.98      0.98       880\n",
      "           6       0.98      0.98      0.98       959\n",
      "           7       0.97      0.97      0.97      1029\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.97      0.97      0.97      1000\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Final cost: 0.0751085162352723\n",
      "Total Accuracy : 0.9764000000000003\n"
     ]
    }
   ],
   "source": [
    "#using the latest(best) Ws, bs value to calculate the output of the test cases\n",
    "\n",
    "layers_dims = [784, 150, 10]\n",
    "L=len(layers_dims)-1\n",
    "m=X_test.shape[1]\n",
    "A[0]=X_test\n",
    "\n",
    "for i in range (1,L):\n",
    "    Z[i] = np.matmul(W[i], A[i-1]) + b[i]\n",
    "    A[i] = relu(Z[i])\n",
    "    \n",
    "Z[L] = np.matmul(W[L], A[L-1]) + b[L]\n",
    "A[L] = np.exp(Z[L]) / np.sum(np.exp(Z[L]), axis=0)\n",
    "\n",
    "cost = compute_multiclass_loss(Y_test, A[L])\n",
    "\n",
    "predictions = np.argmax(A[L], axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))\n",
    "print(\"Final cost:\", cost)\n",
    "print('Total Accuracy :',np.sum((predictions == labels)/m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the next command to create the files containing the weights and bias to be used for the next time\n",
    "#it can also be used to load parameters in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('W_weights.npy',W)\n",
    "np.save('b_bias.npy',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
