{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opencv Drawing pad to get input images \n",
    "#Same as opencv drawing pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_number(event,x,y,flags,param):\n",
    "    \n",
    "    global draw\n",
    "    global prev_point\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:     #left click pressed in\n",
    "        draw = True\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:     #mouse movement,present location in x,y\n",
    "        if draw == True and prev_point != None:\n",
    "                cv2.line(draw_pad,prev_point, (x,y),(255),10)  #draws line joining prev_point to point\n",
    "        prev_point = (x,y)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:    #left click released\n",
    "        draw = False\n",
    "        \n",
    "    \n",
    "events = [i for i in dir(cv2) if 'EVENT' in i]\n",
    "draw_pad = np.zeros((512,512))\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_number)\n",
    "\n",
    "prev_point = None\n",
    "draw = False\n",
    "while(1):\n",
    "    cv2.imshow('image', draw_pad)\n",
    "    if cv2.waitKey(20) & 0xFF == 13:  # ascii(enter key) = 13, press enter key to quit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the input image to MNIST image\n",
    "#Image Preprocessing starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite('original_image.png',draw_pad)\n",
    "#img=cv2.imread('original_image.png',0)\n",
    "#print(img.shape,type(img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crops the image ,removing the excess the drawpad area at the edges\n",
    "def crop_image(img):\n",
    "    for i in range(0,img.shape[0]):\n",
    "        flag_up = np.any(img[i,:])\n",
    "    \n",
    "        if flag_up == True:\n",
    "            up = i\n",
    "            break\n",
    "\n",
    "    for i in reversed(range(0,img.shape[0])):\n",
    "        flag_down = np.any(img[i,:])\n",
    "    \n",
    "        if flag_down == True:\n",
    "            down = i\n",
    "            break\n",
    "        \n",
    "    for i in range(0,img.shape[1]):\n",
    "        flag_left = np.any(img[:,i])\n",
    "    \n",
    "        if flag_left == True:\n",
    "            left = i\n",
    "            break\n",
    "\n",
    "    for i in reversed(range(0,img.shape[1])):\n",
    "        flag_right = np.any(img[:,i])\n",
    "    \n",
    "        if flag_right == True:\n",
    "            right = i\n",
    "            break\n",
    "        \n",
    "    crop = img[up:down,left:right]\n",
    "\n",
    "    height = down - up\n",
    "    width = right - left\n",
    "    #cv2.imwrite('2crop.png',crop)\n",
    "    return crop,height,width\n",
    "\n",
    "#resizes image like a MNIST image\n",
    "def resize_image(img,height,width):\n",
    "\n",
    "    aspect_ratio = float(height/width)\n",
    "    #type(img)\n",
    "    \n",
    "    if height > width:\n",
    "        new_width = int(round(20 / aspect_ratio, 0))  #rounding off width with 0 decimal places,ie nearest int\n",
    "        if (new_width == 0):  # rare case but minimum should be 1 pixel\n",
    "            new_width = 1\n",
    "\n",
    "        dim = (new_width, 20)   #image resized to fit in 20*20 box maintaining the aspect ratio\n",
    "        im = cv2.resize(img, dim)\n",
    "        #cv2.imwrite('3mini.png',im)\n",
    "        wleft = 28 - new_width  # calculate vertical pozition\n",
    "        #resizing to 28*28\n",
    "        \n",
    "        if wleft % 2 == 0:\n",
    "            #adding extra pixels line after the edges to convert image to 28*28\n",
    "            #equal lines added to width from top and bottom\n",
    "            newImage = cv2.copyMakeBorder(im,4,4,int(wleft/2),int(wleft/2), borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "            \n",
    "        else:\n",
    "            #adding extra pixels line after the edges to convert image to 28*28\n",
    "            # UN-equal lines added to width from top and bottom\n",
    "            newImage = cv2.copyMakeBorder(im, 4, 4, int(round((wleft-1)/2, 0)), int(round((wleft-1)/2, 0)) +1, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "            \n",
    "    elif width > height:\n",
    "        \n",
    "        new_height = int(round(20 * aspect_ratio, 0))  # rounding off width with 0 decimal places,ie nearest int\n",
    "        if (new_height == 0):  # rare case but minimum is 1 pixel\n",
    "            new_height = 1\n",
    "               \n",
    "        dim = (20, new_height)   #image resized to fit in 20*20 box maintaining the aspect ratio\n",
    "        im = cv2.resize(img, dim)\n",
    "        #cv2.imwrite('3mini.png',im)\n",
    "        hleft = 28 - new_height  # calculate vertical pozition\n",
    "        \n",
    "        if hleft % 2 == 0:\n",
    "            newImage = cv2.copyMakeBorder(im, int(hleft/2), int(hleft/2), 4, 4, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "        else:\n",
    "            newImage = cv2.copyMakeBorder(im, int(round((hleft-1)/2, 0)), int(round((hleft-1)/2, 0)) +1, 4, 4, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "            \n",
    "    else: #the cases where cropped image is a square\n",
    "        dim = (20,20)\n",
    "        im=cv2.resize(img,dim)\n",
    "        #cv2.imwrite('3mini.png',im)\n",
    "        newImage = cv2.copyMakeBorder(im, 4, 4, 4, 4, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "        \n",
    "    #cv2.imwrite('4Preprocessed_image.png',newImage)\n",
    "    return newImage\n",
    "\n",
    "\n",
    "#function to combine cropping and resizing\n",
    "#Complete MNIST Image Preprocessing\n",
    "def preprocess(img):\n",
    "    cropped_image, h, w = crop_image(img)\n",
    "    #print(cropped_image.shape,type(cropped_image))\n",
    "    Final_image =resize_image(cropped_image, h, w)\n",
    "    \n",
    "    return Final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network \n",
    "# Digit Recognition process starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining CNN model structure\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        #x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = draw_pad\n",
    "\n",
    "Final_image =preprocess(img)\n",
    "\n",
    "\n",
    "img_data = torch.from_numpy(Final_image).view(1,1,28,28)  #converting image data to tensor\n",
    "\n",
    "#Loading the saved model\n",
    "net = torch.load('CNN_MNIST.pth')\n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5\n"
     ]
    }
   ],
   "source": [
    "#predicting the result using the loaded CNN model\n",
    "pred = net(img_data.float())\n",
    "\n",
    "print(\"Prediction:\",int(pred.argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
