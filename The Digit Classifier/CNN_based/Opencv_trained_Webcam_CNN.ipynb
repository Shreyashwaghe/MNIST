{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object used is circular in shape with one side coloured blue(to be detected)\n",
    "#while other is black(not to be detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSV Color thresholds to identify the object color to be detected, here blue faced circular object\n",
    "#NOTE- opencv uses hsv in range 0-180 for H, 0-255 for S,V\n",
    "color_min = np.array([100, 150, 80])\n",
    "color_max = np.array([180, 255, 200])\n",
    "\n",
    "#draw_area contains the detected object which is used to draw numbers\n",
    "draw_area = np.zeros((480,640,3), dtype = np.uint8)\n",
    "\n",
    "#draw_pad contains the drawn number which is merged with the webcam feed to show the number on screen\n",
    "draw_pad = np.zeros((480,640,3), dtype = np.uint8)\n",
    "\n",
    "#filter for dilate/erode\n",
    "filter = np.ones((5,5),np.uint8)\n",
    "\n",
    "#stores the coordinates of prev_center\n",
    "prev_center = None\n",
    "\n",
    "#stores the last predicted value\n",
    "predict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the CNN model structure\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding = 0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        #x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the trained model\n",
    "net = torch.load('CNN_MNIST.pth')\n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crops the image ,removing the excess the drawpad area at the edges\n",
    "def crop_image(img):\n",
    "    for i in range(0,img.shape[0]):\n",
    "        flag_up = np.any(img[i,:])\n",
    "    \n",
    "        if flag_up == True:\n",
    "            up = i\n",
    "            break\n",
    "\n",
    "    for i in reversed(range(0,img.shape[0])):\n",
    "        flag_down = np.any(img[i,:])\n",
    "    \n",
    "        if flag_down == True:\n",
    "            down = i\n",
    "            break\n",
    "        \n",
    "    for i in range(0,img.shape[1]):\n",
    "        flag_left = np.any(img[:,i])\n",
    "    \n",
    "        if flag_left == True:\n",
    "            left = i\n",
    "            break\n",
    "\n",
    "    for i in reversed(range(0,img.shape[1])):\n",
    "        flag_right = np.any(img[:,i])\n",
    "    \n",
    "        if flag_right == True:\n",
    "            right = i\n",
    "            break\n",
    "        \n",
    "    crop = img[up:down,left:right]\n",
    "\n",
    "    height = down - up\n",
    "    width = right - left\n",
    "    #cv2.imwrite('2crop.png',crop)\n",
    "    return crop,height,width\n",
    "\n",
    "#resizes image like a MNIST image\n",
    "def resize_image(img,height,width):\n",
    "\n",
    "    aspect_ratio = float(height/width)\n",
    "    #type(img)\n",
    "    \n",
    "    if height > width:\n",
    "        new_width = int(round(20 / aspect_ratio, 0))  #rounding off width with 0 decimal places,ie nearest int\n",
    "        if (new_width == 0):  # rare case but minimum should be 1 pixel\n",
    "            new_width = 1\n",
    "\n",
    "        dim = (new_width, 20)   #image resized to fit in 20*20 box maintaining the aspect ratio\n",
    "        im = cv2.resize(img, dim)\n",
    "        #cv2.imwrite('3mini.png',im)\n",
    "        wleft = 28 - new_width  # calculate vertical pozition\n",
    "        #resizing to 28*28\n",
    "        \n",
    "        if wleft % 2 == 0:\n",
    "            #adding extra pixels line after the edges to convert image to 28*28\n",
    "            #equal lines added to width from top and bottom\n",
    "            newImage = cv2.copyMakeBorder(im,4,4,int(wleft/2),int(wleft/2), borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "            \n",
    "        else:\n",
    "            #adding extra pixels line after the edges to convert image to 28*28\n",
    "            # UN-equal lines added to width from top and bottom\n",
    "            newImage = cv2.copyMakeBorder(im, 4, 4, int(round((wleft-1)/2, 0)), int(round((wleft-1)/2, 0)) +1, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "            \n",
    "    elif width > height:\n",
    "        \n",
    "        new_height = int(round(20 * aspect_ratio, 0))  # rounding off width with 0 decimal places,ie nearest int\n",
    "        if (new_height == 0):  # rare case but minimum is 1 pixel\n",
    "            new_height = 1\n",
    "               \n",
    "        dim = (20, new_height)   #image resized to fit in 20*20 box maintaining the aspect ratio\n",
    "        im = cv2.resize(img, dim)\n",
    "        #cv2.imwrite('3mini.png',im)\n",
    "        hleft = 28 - new_height  # calculate vertical pozition\n",
    "        \n",
    "        if hleft % 2 == 0:\n",
    "            newImage = cv2.copyMakeBorder(im, int(hleft/2), int(hleft/2), 4, 4, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "        else:\n",
    "            newImage = cv2.copyMakeBorder(im, int(round((hleft-1)/2, 0)), int(round((hleft-1)/2, 0)) +1, 4, 4, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "            \n",
    "    else: #the cases where cropped image is a square\n",
    "        dim = (20,20)\n",
    "        im=cv2.resize(img,dim)\n",
    "        #cv2.imwrite('3mini.png',im)\n",
    "        newImage = cv2.copyMakeBorder(im, 4, 4, 4, 4, borderType= cv2.BORDER_CONSTANT, value=0)\n",
    "        \n",
    "    #cv2.imwrite('4Preprocessed_image.png',newImage)\n",
    "    return newImage\n",
    "\n",
    "\n",
    "#function to combine cropping and resizing\n",
    "#Complete MNIST Image Preprocessing\n",
    "def preprocess(img):\n",
    "    cropped_image, h, w = crop_image(img)\n",
    "    #print(cropped_image.shape,type(cropped_image))\n",
    "    Final_image =resize_image(cropped_image, h, w)\n",
    "    \n",
    "    return Final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the number using the CNN model\n",
    "def prediction(img):\n",
    "    \n",
    "    #converting the drawn image to tensor\n",
    "    img_data = torch.from_numpy(img).view(1,1,28,28)\n",
    "    \n",
    "    pred = net(img_data.float())\n",
    "\n",
    "    return pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring the webcam input\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    (grabbed, frame) = camera.read()               #frame contains the captured webcam frame\n",
    "    frame = cv2.flip(frame, 1)                     #flips webcam frame as they are captured as mirror-image,\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)   #converts bgr frame to hsv frame\n",
    "    \n",
    "    #Finds the pixels having color in the specified range\n",
    "    draw_area = cv2.inRange(hsv,color_min,color_max)\n",
    "    \n",
    "    #getting rid of small unnecessary pixel regions satisfying the color\n",
    "    draw_area = cv2.erode(draw_area, filter, iterations =5)\n",
    "    draw_area = cv2.dilate(draw_area, filter, iterations =5)\n",
    "    \n",
    "    #finds contour of the remaining regions satisfying the color \n",
    "    (contour, hierarchy) = cv2.findContours(draw_area.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #Merges the drawn number with the webcam feed\n",
    "    frame_drawing = cv2.bitwise_or(frame, draw_pad)\n",
    "    \n",
    "    if len(contour) > 0:\n",
    "        \n",
    "        #ASSUMING the max contour is of the object to be detected\n",
    "        max_contour = max(contour, key = cv2.contourArea)\n",
    "        \n",
    "        # finds the center of the object to be detected and draws its approx contour \n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(max_contour)\n",
    "        center = int(x), int(y)\n",
    "        cv2.circle(frame_drawing, center, int(radius), (0,0,0), 10)          \n",
    "        \n",
    "        #for irregular shaped object to be detected , use this code\n",
    "        #cv2.drawContours(frame_drawing, contour, -1, (0, 0, 0), 10)\n",
    "        #M=cv2.moments(boundary)\n",
    "        #center = ( int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "\n",
    "        if prev_center != None:\n",
    "            #draws line joining prev_center to the present center\n",
    "            cv2.line(draw_pad,prev_center, center,(255, 255, 255),15)  \n",
    "            \n",
    "        prev_center = center\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xff == 13: # assess your written digit,\n",
    "        #ascii(enter key) == 13\n",
    "        \n",
    "        #converting 3-channel(rgb) drawn number/image to 0s and 1s ONLY, black or white\n",
    "        draw_pad_gray = cv2.cvtColor(draw_pad, cv2.COLOR_BGR2GRAY)\n",
    "        (th, draw_pad) = cv2.threshold(draw_pad_gray, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        #converting the drawn image to MNIST image\n",
    "        image = preprocess(draw_pad)\n",
    "        \n",
    "        #Predicting the number drawn using the loaded CNN model\n",
    "        predict = int(prediction(image))\n",
    "        \n",
    "        #Clearing draw_pad to get another drawn image\n",
    "        draw_pad = np.zeros((480,640,3), dtype = np.uint8)\n",
    "        prev_center = None\n",
    "     \n",
    "    display = \"Prediction : \" + str(predict)\n",
    "    \n",
    "    cv2.putText(frame_drawing, display, (5, 420), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Real Time Digit Recognition',frame_drawing)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'): # quits/stops the webcam feed, Press 'q' key\n",
    "        break\n",
    "        \n",
    "#Releases the webcam occupied memory\n",
    "camera.release()\n",
    "\n",
    "#Closes all windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "            \n",
    "                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
